<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="http://pyvideo.org/" rel="alternate"></link><link href="http://pyvideo.org/feeds/tag_pytorch.atom.xml" rel="self"></link><id>http://pyvideo.org/</id><updated>2018-05-11T00:00:00+00:00</updated><entry><title>Exploring Deep Learning Framework PyTorch</title><link href="http://pyvideo.org/pycon-us-2018/exploring-deep-learning-framework-pytorch.html" rel="alternate"></link><published>2018-05-11T00:00:00+00:00</published><updated>2018-05-11T00:00:00+00:00</updated><author><name>Stephanie Kim</name></author><id>tag:pyvideo.org,2018-05-11:pycon-us-2018/exploring-deep-learning-framework-pytorch.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Anyone who is interested in deep learning has gotten their hands dirty playing around with Tensorflow, Google's open source deep learning framework. Tensorflow has its benefits like wide scale adoption, deployment on mobile, and support for distributed computing, but it also has a somewhat challenging learning curve, is difficult to debug, and hard to deploy in production. PyTorch is a new deep learning framework that solves a lot of those problems.&lt;/p&gt;
&lt;p&gt;PyTorch is only in beta, but users are rapidly adopting this modular deep learning framework. PyTorch supports tensor computation and dynamic computation graphs that allow you to change how the network behaves on the fly unlike static graphs that are used in frameworks such as Tensorflow. PyTorch offers modularity which enhances the ability to debug or see within the network and for many, is more intuitive to learn than Tensorflow.&lt;/p&gt;
&lt;p&gt;This talk will objectively look at PyTorch and why it might be the best fit for your deep learning use case and we'll look at use cases that will showcase why you might want consider using Tensorflow instead.&lt;/p&gt;
</summary><category term="pytorch"></category></entry><entry><title>Really Deep Neural Networks with PyTorch</title><link href="http://pyvideo.org/pycon-de-2017/really-deep-neural-networks-with-pytorch.html" rel="alternate"></link><published>2017-10-25T00:00:00+00:00</published><updated>2017-10-25T00:00:00+00:00</updated><author><name>David Dao</name></author><id>tag:pyvideo.org,2017-10-25:pycon-de-2017/really-deep-neural-networks-with-pytorch.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;David Dao&lt;/strong&gt; (&amp;#64;dwddao)&lt;/p&gt;
&lt;p&gt;David is a PhD student at ETH Zurich, working on Deep Reinforcement Learning. Before joining ETH Zurich, he was an autonomous driving researcher at Mercedes-Benz Research in Silicon Valley and a graduate student at the Broad Institute of MIT and Harvard.&lt;/p&gt;
&lt;p&gt;David is a firm believer in open source and is organising Germany's largest deep learning meetup series, and Silicon Valley's self-driving AI series. He is a contributor to popular machine intelligence frameworks such as TensorFlow and PyTorch and speaks chinese with swabian accent.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Modern neural networks have hundreds of layers! How can we train such deep networks? Simply stacking layers on top doesn't work! This talk introduces the deep learning library PyTorch by explaining the exciting math, cool ideas and simple code behind what makes really deep neural networks work.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Description&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Modern neural networks consist of hundreds of computation layers! These very deep architectures consistently outperform shallower networks in a variety of tasks. However just simply stacking layers on top of each other won't work because the gradients are either vanishing or exploding during optimisation procedure. This talk explains the exciting math, cool ideas and elegant code that modern neural network architectures such as ResNets, HighwayNets and DenseNets are applying to circumvent the problem using PyTorch. PyTorch is a relatively new deep learning framework that is deeply integrated into Python. Unlike other frameworks such as TensorFlow and Theano, it uses tape-based automatic differentiation to run computation immediately, supports dynamic neural networks and provides a powerful GPU-accelerated Tensor library. The talk concludes with some real-world use-cases for very deep neural networks in chemical-genetic profiling and autonomous driving.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Recorded at&lt;/strong&gt; PyCon.DE 2017 Karlsruhe: &lt;a class="reference external" href="https://de.pycon.org/"&gt;https://de.pycon.org/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Video editing&lt;/strong&gt;: Sebastian Neubauer &amp;amp; Andrei Dan&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tools&lt;/strong&gt;: Blender, Avidemux &amp;amp; Sonic Pi&lt;/p&gt;
</summary><category term="deep learning"></category><category term="ai"></category><category term="machine learning"></category><category term="python"></category><category term="autonomous-driving"></category><category term="pytorch"></category></entry><entry><title>Keynote: PyTorch: a framework for fast, dynamic deep learning and scientific computi</title><link href="http://pyvideo.org/euroscipy-2017/keynote-pytorch-a-framework-for-fast-dynamic-deep-learning-and-scientific-computi.html" rel="alternate"></link><published>2017-08-31T00:00:00+00:00</published><updated>2017-08-31T00:00:00+00:00</updated><author><name>Soumith Chintala</name></author><id>tag:pyvideo.org,2017-08-31:euroscipy-2017/keynote-pytorch-a-framework-for-fast-dynamic-deep-learning-and-scientific-computi.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In this session, you shall be introduced to a new framework for
scientific computing, mainly
aimed at deep learning workloads. The framework consists of an ndarray
library that natively
supports GPU execution, an automatic differentiation engine that is
flexible and fast, and
an optimization package for gradient based optimization methods. We
shall discuss practical
workflows, our features on top of python multiprocessing for efficient
parallel data loaders
and finally we shall briefly look at our upcoming just-in-time Tensor
compiler to fuse
computations and execute them more efficiently.&lt;/p&gt;
&lt;div class="section" id="biographical-sketch"&gt;
&lt;h4&gt;Biographical sketch&lt;/h4&gt;
&lt;p&gt;Soumith Chintala is a Researcher at Facebook AI Research, where he
works on deep learning,
reinforcement learning, generative image models, agents for video
games and large-scale
high-performance deep learning. Prior to joining Facebook in August
2014, he worked at
MuseAmi, where he built deep learning models for music and vision
targeted at mobile
devices. He holds a Masters in CS from NYU, and spent time in Yann
LeCun's NYU lab building
deep learning models for pedestrian detection, natural image OCR,
depth-images among others.&lt;/p&gt;
&lt;p&gt;(Reproduced from &lt;a class="reference external" href="https://research.fb.com/people/chintala-soumith/"&gt;https://research.fb.com/people/chintala-soumith/&lt;/a&gt;)&lt;/p&gt;
&lt;/div&gt;
</summary><category term="keynote"></category><category term="pytorch"></category></entry><entry><title>Population Anomaly Detection with PyTorch</title><link href="http://pyvideo.org/pycon-israel-2017/population-anomaly-detection-with-pytorch.html" rel="alternate"></link><published>2017-06-12T00:00:00+00:00</published><updated>2017-06-12T00:00:00+00:00</updated><author><name>David Tolpin</name></author><id>tag:pyvideo.org,2017-06-12:pycon-israel-2017/population-anomaly-detection-with-pytorch.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;We introduce a scheme for population anomaly detection based on gaussianization through an adversarial autoencoder. This scheme is applicable to detection of 'soft' anomalies in arbitrarily distributed highly-dimensional data. A soft, or population, anomaly is characterized by a shift in the distribution of the data set, where certain elements appear with higher or lower probability than anticipated. Such anomalies must be detected by considering a large sample set rather than a single sample. Applications include, but not limited to, payment fraud trends, data exfiltration, and system security and health monitoring. We evaluate the scheme on credit card payment and DNS data exfiltration data and obtain both quantitative results and qualitative insights. We discuss our PyTorch implementation of deep gaussianization, and review implementation details, pitfalls, and performance.&lt;/p&gt;
</summary><category term="pytorch"></category></entry></feed>