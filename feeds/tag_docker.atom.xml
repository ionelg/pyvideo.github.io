<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="http://pyvideo.org/" rel="alternate"></link><link href="http://pyvideo.org/feeds/tag_docker.atom.xml" rel="self"></link><id>http://pyvideo.org/</id><updated>2018-05-10T00:00:00+00:00</updated><entry><title>Docker for Data Science</title><link href="http://pyvideo.org/pycon-us-2018/docker-for-data-science.html" rel="alternate"></link><published>2018-05-10T00:00:00+00:00</published><updated>2018-05-10T00:00:00+00:00</updated><author><name>Aly Sivji</name></author><id>tag:pyvideo.org,2018-05-10:pycon-us-2018/docker-for-data-science.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Jupyter notebooks simplify the process of developing and sharing Data Science projects across groups and organizations. However, when we want to deploy our work into production, we need to extract the model from the notebook and package it up with the required artifacts (data, dependencies, configurations, etc) to ensure it works in other environments. Containerization technologies such as Docker can be used to streamline this workflow.&lt;/p&gt;
&lt;p&gt;This hands-on tutorial presents Docker in the context of Reproducible Data Science - from idea to application deployment. You will get a thorough introduction to the world of containers; learn how to incorporate Docker into various Data Science projects; and walk through the process of building a Machine Learning model in Jupyter and deploying it as a containerized Flask REST API.&lt;/p&gt;
</summary><category term="jupyter"></category><category term="docker"></category><category term="data science"></category></entry><entry><title>Containerize all the things</title><link href="http://pyvideo.org/caipyra-2016/containerize-all-the-things.html" rel="alternate"></link><published>2016-06-25T00:00:00+00:00</published><updated>2016-06-25T00:00:00+00:00</updated><author><name>Andrews Medina</name></author><id>tag:pyvideo.org,2016-06-25:caipyra-2016/containerize-all-the-things.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Palestra do Andrews Medina no Caipyra 2016:&lt;/p&gt;
&lt;p&gt;Containerize all the things&lt;/p&gt;
&lt;p&gt;Slides: &lt;a class="reference external" href="http://talks.godoc.org/github.com/andrewsmedina/containerize-all-the-things/sample.slide#1"&gt;http://talks.godoc.org/github.com/andrewsmedina/containerize-all-the-things/sample.slide#1&lt;/a&gt;&lt;/p&gt;
</summary><category term="docker"></category><category term="devops"></category></entry><entry><title>Sparking Pandas: an experiment</title><link href="http://pyvideo.org/pycon-italia-2017/sparking-pandas-an-experiment.html" rel="alternate"></link><published>2017-04-07T00:00:00+00:00</published><updated>2017-04-07T00:00:00+00:00</updated><author><name>Francesco Bruni</name></author><id>tag:pyvideo.org,2017-04-07:pycon-italia-2017/sparking-pandas-an-experiment.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Pandas is a good library to deal with tabular data. What if you need to
manage an amount of data that doesn’t fit into memory? What if you want
to “distribute” your computations among multiple machines?&lt;/p&gt;
&lt;p&gt;Starting from a real scenario, Apache Spark will be presented as the
main tool to read and process collected data. It will be shown how a
Pandas-like syntax will come in handy to run aggregations, filtering and
grouping using a Spark Dataframe.&lt;/p&gt;
&lt;p&gt;A previous knowledge of Docker and Docker Compose will be very useful
while knowing MongoDB (where data will be fetched from) is not
mandatory. Basics of functional programming will help to understand
Spark inner logic.&lt;/p&gt;
</summary><category term="microservices"></category><category term="Jupyter"></category><category term="mongodb"></category><category term="data-visualization"></category><category term="data-analysis"></category><category term="spark"></category><category term="docker"></category></entry><entry><title>Dockerizing the Python</title><link href="http://pyvideo.org/pycon-se-2017/dockerizing-the-python.html" rel="alternate"></link><published>2017-09-06T00:00:00+00:00</published><updated>2017-09-06T00:00:00+00:00</updated><author><name>Ambreen Sheikh</name></author><id>tag:pyvideo.org,2017-09-06:pycon-se-2017/dockerizing-the-python.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The focus of this talk will be on building and running python programs in a docker container. A major chunk of the talk will also concentrate on the docker setup &amp;amp; it’s complete echo system. The purpose behind the talk is the demonstrate the usage of docker in everyday python development &amp;amp; deployment environment.&lt;/p&gt;
</summary><category term="docker"></category></entry><entry><title>Extend Docker using Python</title><link href="http://pyvideo.org/pycon-israel-2017/extend-docker-using-python.html" rel="alternate"></link><published>2017-06-13T00:00:00+00:00</published><updated>2017-06-13T00:00:00+00:00</updated><author><name>Boaz Shuster</name></author><id>tag:pyvideo.org,2017-06-13:pycon-israel-2017/extend-docker-using-python.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Docker is the most popular platform to run Python applications within containers. Many companies are using this platform to either deploy micro-services or test the code changes before merging it to production. Docker has 3 extension points: Drivers, Plugins and user-facing API. I am going to focus on the latter (user-facing API) and by the end of the talk, you will learn Docker's REST API and know how to extend Docker capabilities using Python.&lt;/p&gt;
</summary><category term="docker"></category></entry><entry><title>Running jupyter notebook remotely in a docker swarm cluster</title><link href="http://pyvideo.org/pydata-barcelona-2017/running-jupyter-notebook-remotely-in-a-docker-swarm-cluster.html" rel="alternate"></link><published>2017-05-20T15:00:00+02:00</published><updated>2017-05-20T15:00:00+02:00</updated><author><name>Jordi Deu-Pons</name></author><id>tag:pyvideo.org,2017-05-20:pydata-barcelona-2017/running-jupyter-notebook-remotely-in-a-docker-swarm-cluster.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The current version of Jupyter Notebook computes the document state at the browser side, this is a problem if you run long jobs in a remote notebook from a laptop. If you close the browser you lose all the output of the current running cell. I will explain how we solved this problem in our lab. This solution it also allows a &amp;quot;walkie-talkie&amp;quot; like real-time collaboration.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The solution is based on running a docker container with a browser and a VNC server. All the remote access to the notebooks is done using Apache Guacamole a clientless remote desktop gateway. Everything is running on a dynamic docker swarm cluster of 20 nodes. As a lateral effect, this solution it also allows a real-time collaboration between users in a way that multiple users can access at the same time the same desktop (but they have to fight for the mouse and the keyboard).&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://github.com/jordeu/pytalks/tree/master/20170520_pydata_jupyter_in_a_docker_cluster"&gt;https://github.com/jordeu/pytalks/tree/master/20170520_pydata_jupyter_in_a_docker_cluster&lt;/a&gt;&lt;/p&gt;
</summary><category term="jupyter notebook"></category><category term="docker"></category><category term="swarm"></category></entry><entry><title>DIY Serverless Platform with Python3 and Docker</title><link href="http://pyvideo.org/pycon-jamaica-2016/diy-serverless-platform-with-python3-and-docker.html" rel="alternate"></link><published>2016-11-18T00:00:00+00:00</published><updated>2016-11-18T00:00:00+00:00</updated><author><name>Joir-dan Gumbs</name></author><id>tag:pyvideo.org,2016-11-18:pycon-jamaica-2016/diy-serverless-platform-with-python3-and-docker.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;A walkthrough on how I built my own serverless platform to run both ephemeral and long-lasting functions in Python on top of Docker, capable of handling REST and websocket connections. Will go over architecture, show code, and discuss pain points as well as next steps.  #pyconjamaica2016&lt;/p&gt;
</summary><category term="Serverless"></category><category term="Docker"></category></entry><entry><title>Dev Ops meets Data Science Taking models from prototype to production with Docker</title><link href="http://pyvideo.org/pydata-dc-2016/dev-ops-meets-data-science-taking-models-from-prototype-to-production-with-docker.html" rel="alternate"></link><published>2016-10-09T00:00:00+00:00</published><updated>2016-10-09T00:00:00+00:00</updated><author><name>Andy Terrel</name></author><id>tag:pyvideo.org,2016-10-09:pydata-dc-2016/dev-ops-meets-data-science-taking-models-from-prototype-to-production-with-docker.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData DC 2016&lt;/p&gt;
&lt;p&gt;We present the evolution of a model to a production API that can scale to large e-commerce needs. On the journey we discuss metrics of success and how to use the Kubernetes cluster manager and associated tools for deploy. In addition to the use of these tools we highlight how to make use of the cluster management system for further testing and experimentation with your models.&lt;/p&gt;
&lt;p&gt;The chasm between data science and dev ops is often wide and impenetrable, but the two fields have more in common than meets the eye. Every data scientist will be able to lean in and help their career by investing in a basic understanding the basic principles of dev ops. In this talk I present the notions of service level indicators, objectives, and agreements. I cover the rigorous monitoring and testing of services. Finally we demonstrate how to build a basic data science workflow and push to production level APIs with Docker and Kubernetes.&lt;/p&gt;
&lt;p&gt;Kubernetes is an opinionated container cluster manager with an easy to use, robust interface. It can be use on very small and very large clusters. Docker is a container system that allows one to build code in an isolated environment. Paired with a container manager such as Kubernetes we are able to manage millions of instances as needed for a production deployment. These tools are two of many different options but are considered among the best open source solutions available.&lt;/p&gt;
</summary><category term="Data"></category><category term="data science"></category><category term="docker"></category><category term="models"></category><category term="science"></category></entry><entry><title>Setting up predictive analytics services with Palladium</title><link href="http://pyvideo.org/pydata-berlin-2016/setting-up-predictive-analytics-services-with-palladium.html" rel="alternate"></link><published>2016-06-07T00:00:00+00:00</published><updated>2016-06-07T00:00:00+00:00</updated><author><name>Andreas Lattner</name></author><id>tag:pyvideo.org,2016-06-07:pydata-berlin-2016/setting-up-predictive-analytics-services-with-palladium.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Description&lt;/p&gt;
&lt;p&gt;We will introduce Palladium, an open source framework for setting up predictive analytics services. It supports tasks like fitting, evaluating, storing, and distributing (predictive) models. Core ML processes are compatible with scikit-learn and a large number of scikit-learn’s features can be used. Besides the use of Palladium we will also show how to use it with Docker and Mesos / Marathon.&lt;/p&gt;
&lt;p&gt;Abstract&lt;/p&gt;
&lt;p&gt;In this talk, we will introduce Palladium, an open source framework for easily setting up predictive analytics services (&lt;a class="reference external" href="https://github.com/ottogroup/palladium"&gt;https://github.com/ottogroup/palladium&lt;/a&gt;). It supports tasks like fitting, evaluating, storing, distributing, and updating (predictive) models. Core machine learning processes are compatible with the open source machine learning library scikit-learn and thus, a large number of scikit-learn’s features can be used with Palladium. Although being implemented in Python, Palladium provides support for other languages and is shipped with examples how to integrate and expose R and Julia models. For an efficient deployment of services based on Palladium, a script to create Docker images automatically is provided. This talk will cover the use of Palladium including an example where a simple classification service is set up. We will also show how Docker and Mesos / Marathon can be used to deploy and scale Palladium-based services. Having basic knowledge about Machine Learning and/or scikit-learn would be an advantage when attending this talk.&lt;/p&gt;
</summary><category term="palladium"></category><category term="scikit-learn"></category><category term="docker"></category><category term="mesos"></category><category term="marathon"></category><category term="machine learning"></category></entry><entry><title>Building Python apps with Docker</title><link href="http://pyvideo.org/pytexas-2015/building-python-apps-with-docker.html" rel="alternate"></link><published>2015-10-09T00:00:00+00:00</published><updated>2015-10-09T00:00:00+00:00</updated><author><name>Mark Adams</name></author><id>tag:pyvideo.org,2015-10-09:pytexas-2015/building-python-apps-with-docker.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;If you haven't heard of Docker yet, its a great tool that allows you
wrap up your app and everything it needs to run: code, runtime, and even
system libraries and guarantee that it will always run the same,
regardless of the environment (local machine, server, or even the
cloud). Whether you're deploying a web app, performing data analysis, or
creating local environments for your dev team or CI builds, Docker can
help.&lt;/p&gt;
&lt;p&gt;I'll give an introduction to Docker, an overview of some of the current
tools in the Docker ecosystem (Docker Machine and Docker Compose) and
demonstrate how to create, build, and deploy Python applications using
Docker.&lt;/p&gt;
&lt;p&gt;This talk is targeted towards web developers, data scientists, or really
anyone who develops using Python that would like to learn more about
Docker and how it can help their projects.&lt;/p&gt;
</summary><category term="Docker"></category></entry></feed>