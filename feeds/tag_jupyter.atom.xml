<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="http://pyvideo.org/" rel="alternate"></link><link href="http://pyvideo.org/feeds/tag_jupyter.atom.xml" rel="self"></link><id>http://pyvideo.org/</id><updated>2018-05-10T00:00:00+00:00</updated><entry><title>Docker for Data Science</title><link href="http://pyvideo.org/pycon-us-2018/docker-for-data-science.html" rel="alternate"></link><published>2018-05-10T00:00:00+00:00</published><updated>2018-05-10T00:00:00+00:00</updated><author><name>Aly Sivji</name></author><id>tag:pyvideo.org,2018-05-10:pycon-us-2018/docker-for-data-science.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Jupyter notebooks simplify the process of developing and sharing Data Science projects across groups and organizations. However, when we want to deploy our work into production, we need to extract the model from the notebook and package it up with the required artifacts (data, dependencies, configurations, etc) to ensure it works in other environments. Containerization technologies such as Docker can be used to streamline this workflow.&lt;/p&gt;
&lt;p&gt;This hands-on tutorial presents Docker in the context of Reproducible Data Science - from idea to application deployment. You will get a thorough introduction to the world of containers; learn how to incorporate Docker into various Data Science projects; and walk through the process of building a Machine Learning model in Jupyter and deploying it as a containerized Flask REST API.&lt;/p&gt;
</summary><category term="jupyter"></category><category term="docker"></category><category term="data science"></category></entry><entry><title>Jupyter Tools for Teaching and Learning</title><link href="http://pyvideo.org/pycon-us-2018/jupyter-tools-for-teaching-and-learning.html" rel="alternate"></link><published>2018-05-10T00:00:00+00:00</published><updated>2018-05-10T00:00:00+00:00</updated><author><name>Douglas Blank</name></author><id>tag:pyvideo.org,2018-05-10:pycon-us-2018/jupyter-tools-for-teaching-and-learning.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Project Jupyter is the center of a set of technologies that grew out of simple tools to make Python easier to use. Today, Jupyter is composed of powerful client-server applications and protocols for computing in many programming languages. This talk focuses on using these technologies for pedagogical purposes.&lt;/p&gt;
&lt;p&gt;Every course I have taught since the Fall semester of 2014 has been over the web via our JupyterHub server. These courses have included firstyear writing seminars, as well as courses in Programming Languages, Assembly Language, Introduction to Biology (in Python), and in Processing (Java-based). In this talk I hope to help identify best-practices for using Jupyter in the classroom. I will discuss and demonstrate tools and techniques, and explore the challenges of using Jupyter for teaching and learning.&lt;/p&gt;
</summary><category term="jupyter"></category></entry><entry><title>Integrating Jupyter Notebooks into your Infrastructure</title><link href="http://pyvideo.org/pycon-de-2017/integrating-jupyter-notebooks-into-your-infrastructure.html" rel="alternate"></link><published>2017-10-25T00:00:00+00:00</published><updated>2017-10-25T00:00:00+00:00</updated><author><name>Florian Rhiem</name></author><id>tag:pyvideo.org,2017-10-25:pycon-de-2017/integrating-jupyter-notebooks-into-your-infrastructure.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Florian Rhiem&lt;/strong&gt; (&amp;#64;FlorianRhiem)&lt;/p&gt;
&lt;p&gt;Florian Rhiem is a scientific software developer at Forschungszentrum Jülich in the Scientific IT-Systems department of Peter Grünberg Institute / Jülich Centre for Neutron Science. In 2014, he finished his master's thesis on visualization of multidimensional functions and graduated as Master of Science in Technomathematics. He works with Python and C, mostly focusing on 3D visualization software.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Jupyter Notebooks combine executable code and rich text elements in a web application. In this talk you will learn how a custom JupyterHub installation can be used to integrate Jupyter Notebooks into your infrastructure, including existing authentication methods and custom software distributions.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Description&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Jupyter Notebooks allow you to create and share interactive documents containing both rich text and executable code. As researchers, you can write Notebooks that allow your readers to reproduce your results on their own. As data scientists, you can use interactive visualizations to explore and analyze data sets directly in your browser. With official support for Python, Julia and R and community support for programming languages ranging from Fortran to JavaScript, Jupyter can be used in a wide variety of workflows.&lt;/p&gt;
&lt;p&gt;In this talk, you will learn how a custom JupyterHub installation has been used to seamlessly integrate Jupyter Notebooks into the existing infrastructure at the Jülich Centre for Neutron Science and the Peter Grünberg Institute. After introducing JupyterHub and its components, the presentation will show how each can be customized to use already existing resources and services, such as LDAP authentication, NFS-based storage and custom software distributions.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Recorded at&lt;/strong&gt; PyCon.DE 2017 Karlsruhe: &lt;a class="reference external" href="https://de.pycon.org/"&gt;https://de.pycon.org/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Video editing&lt;/strong&gt;: Sebastian Neubauer &amp;amp; Andrei Dan&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tools&lt;/strong&gt;: Blender, Avidemux &amp;amp; Sonic Pi&lt;/p&gt;
</summary><category term="jupyterhub"></category><category term="jupyter"></category><category term="use-case"></category></entry><entry><title>Jupyter: if you don't use it yet you're doing wrong</title><link href="http://pyvideo.org/pycon-italia-2017/jupyter-if-you-dont-use-it-yet-youre-doing-wrong.html" rel="alternate"></link><published>2017-04-08T00:00:00+00:00</published><updated>2017-04-08T00:00:00+00:00</updated><author><name>Christian Barra</name></author><id>tag:pyvideo.org,2017-04-08:pycon-italia-2017/jupyter-if-you-dont-use-it-yet-youre-doing-wrong.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Have you ever heard about Jupyter Notebook ? It’s like Python REPL on
steroids !&lt;/p&gt;
&lt;p&gt;In this talk I will introduce the Jupyter project, the libraries behind
this project and how you can use Jupyter Notebook for a lot of
activities like fast prototyping, data science, education and so on !&lt;/p&gt;
&lt;p&gt;The talk will be an introduction, Beginners are welcome !&lt;/p&gt;
</summary><category term="iPython"></category><category term="Data-Scientist"></category><category term="Jupyter"></category><category term="pydata"></category></entry><entry><title>Sparking Pandas: an experiment</title><link href="http://pyvideo.org/pycon-italia-2017/sparking-pandas-an-experiment.html" rel="alternate"></link><published>2017-04-07T00:00:00+00:00</published><updated>2017-04-07T00:00:00+00:00</updated><author><name>Francesco Bruni</name></author><id>tag:pyvideo.org,2017-04-07:pycon-italia-2017/sparking-pandas-an-experiment.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Pandas is a good library to deal with tabular data. What if you need to
manage an amount of data that doesn’t fit into memory? What if you want
to “distribute” your computations among multiple machines?&lt;/p&gt;
&lt;p&gt;Starting from a real scenario, Apache Spark will be presented as the
main tool to read and process collected data. It will be shown how a
Pandas-like syntax will come in handy to run aggregations, filtering and
grouping using a Spark Dataframe.&lt;/p&gt;
&lt;p&gt;A previous knowledge of Docker and Docker Compose will be very useful
while knowing MongoDB (where data will be fetched from) is not
mandatory. Basics of functional programming will help to understand
Spark inner logic.&lt;/p&gt;
</summary><category term="microservices"></category><category term="Jupyter"></category><category term="mongodb"></category><category term="data-visualization"></category><category term="data-analysis"></category><category term="spark"></category><category term="docker"></category></entry><entry><title>Taming Big Data with Jupyter and Friends</title><link href="http://pyvideo.org/pydata-meetups/taming-big-data-with-jupyter-and-friends.html" rel="alternate"></link><published>2017-03-02T00:00:00+00:00</published><updated>2017-03-02T00:00:00+00:00</updated><author><name>Carol Willing</name></author><id>tag:pyvideo.org,2017-03-02:pydata-meetups/taming-big-data-with-jupyter-and-friends.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;This month, we are excited to host Carol Willing who will be discussing the Jupyter eco-sytem.  Carol develops software, electronics, educational tutorials, and is passionate about outreach.  She is a core developer on the Jupyter Project and is a former director at the Python Software foundation.  She continues to contribute her time to OpenHatch, Systers, PyLadies San Diego, and San Diego Python.&lt;/p&gt;
</summary><category term="jupyter"></category></entry><entry><title>Data Science &amp; Data Visualization in Python. How to harness power of Python for social good?</title><link href="http://pyvideo.org/pydata-berlin-2017/data-science-data-visualization-in-python-how-to-harness-power-of-python-for-social-good.html" rel="alternate"></link><published>2017-06-30T00:00:00+00:00</published><updated>2017-06-30T00:00:00+00:00</updated><author><name>Radovan Kavicky</name></author><id>tag:pyvideo.org,2017-06-30:pydata-berlin-2017/data-science-data-visualization-in-python-how-to-harness-power-of-python-for-social-good.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Python as an Open Data Science tool offers many libraries for data visualization and I will show you how to use and combine the best. I strongly believe that power of data is not only in the information &amp;amp; insight that data can provide us, Data is and can be really beautiful and can not only transform our perception but also the world that we all live in.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In my talk I will primarily focus on answering/offer the answer to these questions:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Why we need data science and why more and more people should be really interested in analyzing data and data visualization? (motivation)&lt;/li&gt;
&lt;li&gt;What is data science and how to start doing it in Python? (introduction of procedures, tools, most popular IDE-s for Python, etc.)&lt;/li&gt;
&lt;li&gt;What tools for data analysis and data visualization Python offers? (in each stage of analysis the best libraries will be shown for the specific purpose; as for data visualization we will focus particularly on Bokeh, Seaborn, Plotly and use of Jupyter Notebook and Plotly)&lt;/li&gt;
&lt;li&gt;How to 'unlock' the insight hidden in data through Python and how to use it to transform not only public administration or business, but ultimately the transformation of the whole society and economy towards the insight &amp;amp; knowledge based? (potential of data science)&lt;/li&gt;
&lt;li&gt;Open Data, Open Government Partnership, Open Public Administration &amp;amp; all the advantages of Open Data Science &amp;amp; Python. Data-Driven Approach. Everywhere. Now. (the end of talk +vision)&lt;/li&gt;
&lt;/ul&gt;
</summary><category term="python"></category><category term="data-science"></category><category term="data-visualization"></category><category term="analytics"></category><category term="PyData"></category><category term="PyDataBLN"></category><category term="PyDataBerlin"></category><category term="PyDataBA"></category><category term="PyDataBratislava"></category><category term="talk"></category><category term="Data"></category><category term="Bokeh"></category><category term="Social Good"></category><category term="datascience"></category><category term="jupyter"></category><category term="open science"></category><category term="open data science"></category><category term="DataVisualization"></category><category term="data-analysis"></category><category term="analysis"></category><category term="matplotlib"></category><category term="numpy"></category><category term="data wrangling"></category><category term="jupyter notebook"></category><category term="pandas"></category><category term="machine learning"></category><category term="deep learning"></category><category term="Open Data"></category><category term="Citizen Data Science"></category></entry><entry><title>Vizic - A Jupyter Based Interactive Visualization Tool for Astronomical Catalogs</title><link href="http://pyvideo.org/scipy-2017/vizic-a-jupyter-based-interactive-visualization-tool-for-astronomical-catalogs.html" rel="alternate"></link><published>2017-07-16T00:00:00+00:00</published><updated>2017-07-16T00:00:00+00:00</updated><author><name>Weixiang Yu</name></author><id>tag:pyvideo.org,2017-07-16:scipy-2017/vizic-a-jupyter-based-interactive-visualization-tool-for-astronomical-catalogs.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In the face of ever-growing datasets in astronomical sky surveys, we present Vizic, a Python/JavaScript library designed for Jupyter Notebook, which visualizes astronomical catalogs and presents them in vectorized form inside widgets in Jupyter notebooks. Visualized catalogs are fully interactive under a tiled web map approach. Vizic provides a unique and efficient way to visualize and explore multiple catalogs through interactive object filtering, color mapping, zooming and data selection using a lasso-like tool. In addition, custom overlays such as Voronoi layer can assist astronomers to visualize and interact with cosmic structures. At the end of this talk, we will give a brief demo to illustrate the potentials of Vizic in scientific research.&lt;/p&gt;
</summary><category term="vizic"></category><category term="jupyter"></category></entry><entry><title>Making your code faster: Cython and parallel processing in the Jupyter Notebook</title><link href="http://pyvideo.org/pydata-dc-2016/making-your-code-faster-cython-and-parallel-processing-in-the-jupyter-notebook.html" rel="alternate"></link><published>2016-10-09T00:00:00+00:00</published><updated>2016-10-09T00:00:00+00:00</updated><author><name>Gustavo Patino</name></author><id>tag:pyvideo.org,2016-10-09:pydata-dc-2016/making-your-code-faster-cython-and-parallel-processing-in-the-jupyter-notebook.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData DC 2016&lt;/p&gt;
&lt;p&gt;Github: &lt;a class="reference external" href="https://github.com/gapatino/Making-Your-Code-Faster-Cython-and-parallel-processing-in-the-Jupyter-Notebook"&gt;https://github.com/gapatino/Making-Your-Code-Faster-Cython-and-parallel-processing-in-the-Jupyter-Notebook&lt;/a&gt;
Slides: &lt;a class="reference external" href="http://www.slideshare.net/PyData/making-your-code-faster-cython-and-parallel-processing-in-the-jupyter-notebook"&gt;http://www.slideshare.net/PyData/making-your-code-faster-cython-and-parallel-processing-in-the-jupyter-notebook&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;As the complexity and scope of applications grow, it is very common to run into slow performance issues. In Python, it is possible to improve the speed of execution with the use of parallel processing and the Cython compiler. The Jupyter Notebook makes the implementation of both of them a relatively simple task, which will be the focus of this session.&lt;/p&gt;
</summary><category term="code"></category><category term="Cython"></category><category term="jupyter"></category><category term="jupyter notebook"></category><category term="notebook"></category><category term="parallel"></category><category term="processing"></category></entry><entry><title>Popping Kernels: An Exploration of Kernel Development for Jupyter Notebooks</title><link href="http://pyvideo.org/pydata-chicago-2016/popping-kernels-an-exploration-of-kernel-development-for-jupyter-notebooks.html" rel="alternate"></link><published>2016-08-26T00:00:00+00:00</published><updated>2016-08-26T00:00:00+00:00</updated><author><name>Safia Abdalla</name></author><id>tag:pyvideo.org,2016-08-26:pydata-chicago-2016/popping-kernels-an-exploration-of-kernel-development-for-jupyter-notebooks.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData Chicago 2016&lt;/p&gt;
&lt;p&gt;This talk will give individuals with no kernel experience and some Python experience, a brief introduction to the concepts they need to understand in order to develop kernels. This talk will also be useful to individuals who are looking for fun projects that will allow them to strengthen their skills in a particular programming language.&lt;/p&gt;
</summary><category term="development"></category><category term="jupyter"></category><category term="jupyter notebook"></category></entry><entry><title>Diffing and Merging Jupyter Notebooks with nbdime</title><link href="http://pyvideo.org/scipy-2016/diffing-and-merging-jupyter-notebooks-with-nbdime-scipy-2016-min-ragan-kelley.html" rel="alternate"></link><published>2016-07-15T00:00:00+00:00</published><updated>2016-07-15T00:00:00+00:00</updated><author><name>Min Ragan Kelley</name></author><id>tag:pyvideo.org,2016-07-15:scipy-2016/diffing-and-merging-jupyter-notebooks-with-nbdime-scipy-2016-min-ragan-kelley.html</id><summary type="html"></summary><category term="SciPy 2016"></category><category term="jupyter"></category><category term="jupyter notebook"></category></entry><entry><title>JupyterLab: Building Blocks for Interactive Computing</title><link href="http://pyvideo.org/scipy-2016/jupyterlab-building-blocks-for-interactive-computing-scipy-2016-brian-granger.html" rel="alternate"></link><published>2016-07-15T00:00:00+00:00</published><updated>2016-07-15T00:00:00+00:00</updated><author><name>Brian Granger</name></author><id>tag:pyvideo.org,2016-07-15:scipy-2016/jupyterlab-building-blocks-for-interactive-computing-scipy-2016-brian-granger.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Project Jupyter provides building blocks for interactive and exploratory computing. These building blocks make science and data science reproducible across over 40 programming language (Python, Julia, R, etc.). Central to the project is the Jupyter Notebook, a web-based interactive computing platform that allows users to author data- and code-driven narratives - computational narratives - that combine live code, equations, narrative text, visualizations, interactive dashboards and other media.&lt;/p&gt;
&lt;p&gt;While the Jupyter Notebook has proved to be an incredibly productive way of working with code and data interactively, it is helpful to decompose notebooks into more primitive building blocks: kernels for code execution, input areas for typing code, markdown cells for composing narrative content, output areas for showing results, terminals, etc. The fundamental idea of JupyterLab is to offer a user interface that allows users to assemble these building blocks in different ways to support interactive workflows that include, but go far beyond, Jupyter Notebooks.&lt;/p&gt;
&lt;p&gt;JupyterLab accomplishes this by providing a modular and extensible user interface that exposes these building blocks in the context of a powerful work space. Users can arrange multiple notebooks, text editors, terminals, output areas, etc. on a single page with multiple panels, tabs, splitters, and collapsible sidebars with a file browser, command palette and integrated help system. The codebase and UI of JupyterLab is based on a flexible plugin system that makes it easy to extend with new components.&lt;/p&gt;
&lt;p&gt;In this talk, we will demonstrate the JupyterLab interface, its codebase, and describe how it fits within the overall roadmap of the project.&lt;/p&gt;
</summary><category term="SciPy 2016"></category><category term="jupyter"></category><category term="jupyterlab"></category><category term="jupyter notebook"></category></entry><entry><title>Keynote: Project Jupyter</title><link href="http://pyvideo.org/scipy-2016/keynote-project-jupyter-scipy-2016-brian-granger.html" rel="alternate"></link><published>2016-07-15T00:00:00+00:00</published><updated>2016-07-15T00:00:00+00:00</updated><author><name>Brian Granger</name></author><id>tag:pyvideo.org,2016-07-15:scipy-2016/keynote-project-jupyter-scipy-2016-brian-granger.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Brian Granger is an Associate Professor of Physics at Cal Poly State University in San Luis Obispo, CA. He has a background in theoretical physics, with a Ph.D from the University of Colorado. His current research interests include quantum computing, parallel and distributed computing and interactive computing environments for scientific computing and data science. He is a leader of the IPython project, co-founder of Project Jupyter and is an active contributor to a number of other open source projects focused on data science in Python. He is a board member of the NumFocus Foundation and a fellow at Cal Poly’s Center for Innovation and Entrepreneurship. He is &amp;#64;ellisonbg on Twitter and GitHub.&lt;/p&gt;
&lt;p&gt;Announcement of Altair, Altair is a declarative statistical visualization library for Python. Altair is developed by Brian Granger and Jake Vanderplas in close collaboration with the UW Interactive Data Lab.&lt;/p&gt;
&lt;p&gt;With Altair, you can spend more time understanding your data and its meaning. Altair's API is simple, friendly and consistent and built on top of the powerful Vega-Lite JSON specification. This elegant simplicity produces beautiful and effective visualizations with a minimal amount of code.&lt;/p&gt;
</summary><category term="SciPy 2016"></category><category term="altair"></category><category term="jupyter"></category><category term="jupyter notebook"></category></entry><entry><title>Proselint: The Linting of Science Prose, and the Science of Prose Linting</title><link href="http://pyvideo.org/scipy-2016/proselint-the-linting-of-science-prose-and-the-science-of-prose-linting-scipy-2016-michael-pac.html" rel="alternate"></link><published>2016-07-15T00:00:00+00:00</published><updated>2016-07-15T00:00:00+00:00</updated><author><name>Michael Pacer</name></author><id>tag:pyvideo.org,2016-07-15:scipy-2016/proselint-the-linting-of-science-prose-and-the-science-of-prose-linting-scipy-2016-michael-pac.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Writing is notoriously hard, even for the best writers, and it's not for lack of good advice — a tremendous amount of knowledge is strewn across usage guides, dictionaries, technical manuals, essays, pamphlets, websites, and the hearts and minds of great authors and editors. But this knowledge is trapped, waiting to be extracted and transformed.&lt;/p&gt;
&lt;p&gt;We built Proselint, a Python-based linter for prose. Proselint identifies violations of expert style and usage guidelines. Proselint is open-source software released under the BSD license and works with Python 2 and 3. It runs as a command-line utility or editor plugin (e.g., Sublime Text, Atom, Vim, Emacs) and outputs advice in standard formats (e.g., JSON). Though in its infancy – perhaps 2% of what it could be – Proselint already includes modules addressing: redundancy, jargon, illogic, clichés, sexism, misspelling, inconsistency, misuse of symbols, malapropisms, oxymorons, security gaffes, hedging, apologizing, pretension.     Proselint can be seen as both a language tool for scientists and a tool for language science. On the one hand, it includes modules that promote clear and consistent prose in science writing. On the other, it measures language usage and explores the factors relevant to creating a useful linter.&lt;/p&gt;
</summary><category term="SciPy 2016"></category><category term="lint"></category><category term="prose"></category><category term="jupyter"></category></entry><entry><title>JupyterHub as an Interactive Supercomputing Gateway</title><link href="http://pyvideo.org/scipy-2016/jupyterhub-as-an-interactive-supercomputing-gateway-scipy-2016-michael-milligan.html" rel="alternate"></link><published>2016-07-14T00:00:00+00:00</published><updated>2016-07-14T00:00:00+00:00</updated><author><name>Michael Milligan</name></author><id>tag:pyvideo.org,2016-07-14:scipy-2016/jupyterhub-as-an-interactive-supercomputing-gateway-scipy-2016-michael-milligan.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;At the Minnesota Supercomputing Institute we are exploring ways to provide the immediacy and flexibility of interactive computing within the batch-scheduled, tightly controlled world of traditional cluster supercomputing. As Jupyter Notebook has gained in popularity, the steps needed to use it within such an environment have proven to be a barrier to entry even as increasingly powerful Python tools have developed to take advantage of large computational resources. JupyterHub to the rescue! Except out of the box, it doesn't know anything about resource types, job submission, and so on. We developed BatchSpawner and friends as a general JupyterHub backend for batch-scheduled environments. In this talk I will walk through how we have deployed JupyterHub to provide a user-friendly gateway to interactive supercomputing.&lt;/p&gt;
</summary><category term="SciPy 2016"></category><category term="hpc"></category><category term="jupyterhub"></category><category term="jupyter"></category><category term="jupyter notebook"></category><category term="supercomputing"></category></entry><entry><title>Reproducible, One Button Workflows with the Jupyter Notebook &amp; Scons</title><link href="http://pyvideo.org/scipy-2016/reproducible-one-button-workflows-with-the-jupyter-notebook-scons-scipy-2016-jessica-hamrick.html" rel="alternate"></link><published>2016-07-14T00:00:00+00:00</published><updated>2016-07-14T00:00:00+00:00</updated><author><name>Jessica Hamrick</name></author><id>tag:pyvideo.org,2016-07-14:scipy-2016/reproducible-one-button-workflows-with-the-jupyter-notebook-scons-scipy-2016-jessica-hamrick.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;What is the best way to develop analysis code in the Jupyter notebook, while managing complex dependencies between analyses? In this talk, I will introduce nbflow, which is a project that integrates a Python-based build system (SCons) with the Jupyter notebook, enabling researchers to easily build sophisticated,
complex analysis pipelines entirely within notebooks while still maintaining a &amp;quot;one-button workflow&amp;quot; in which all analyses can be executed, in the correct order, from a single command. I will show how nbflow can be applied to existing analyses and how it can be used to construct an analysis pipeline stretching the entire way from data cleaning, to computing statistics, to generating figures,
and even to automatically generating LaTeX commands that can be used in publications to format results without the risk of copy-and-paste error.&lt;/p&gt;
</summary><category term="SciPy 2016"></category><category term="jupyter"></category><category term="jupyter notebook"></category><category term="workflow"></category><category term="nbflow"></category></entry></feed>