<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="http://pyvideo.org/" rel="alternate"></link><link href="http://pyvideo.org/feeds/speaker_francoise-provencher.atom.xml" rel="self"></link><id>http://pyvideo.org/</id><updated>2017-06-30T00:00:00+00:00</updated><entry><title>Biases are bugs: algorithm fairness and machine learning ethics</title><link href="http://pyvideo.org/pydata-berlin-2017/biases-are-bugs-algorithm-fairness-and-machine-learning-ethics.html" rel="alternate"></link><published>2017-06-30T00:00:00+00:00</published><updated>2017-06-30T00:00:00+00:00</updated><author><name>Fran√ßoise Provencher</name></author><id>tag:pyvideo.org,2017-06-30:pydata-berlin-2017/biases-are-bugs-algorithm-fairness-and-machine-learning-ethics.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Biases are bugs. They need to be found, fixed, and learnt from. A mix of good ethics and good engineering practices can get us a long way towards that goal.&lt;/p&gt;
&lt;p&gt;In this talk, you'll learn what biases are, what software tools can help, and how to adopt engineering practices that can make your algorithms fairer.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Algorithms can make decisions, and these decisions can have an impact on people's lives. By feeding data into these algorithms, they can reproduce or amplify our societal biases and take unfair decisions.&lt;/p&gt;
&lt;p&gt;Biases are bugs. They need to be found, fixed, and learnt from. A mix of good ethics and good engineering practices can get us a long way towards that goal.&lt;/p&gt;
&lt;p&gt;In this talk, you will learn what biases are, see examples of algorithms gone wrong, and explore some software tools you can use and engineering practices you can adopt in your own work to make your algorithms more fair.&lt;/p&gt;
</summary></entry></feed>