<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="http://pyvideo.org/" rel="alternate"></link><link href="http://pyvideo.org/feeds/speaker_sujit-pal.atom.xml" rel="self"></link><id>http://pyvideo.org/</id><updated>2017-07-06T00:00:00+00:00</updated><entry><title>Applying the four step "Embed, Encode, Attend, Predict" framework to predict document similarity</title><link href="http://pyvideo.org/pydata-seattle-2017/applying-the-four-step-embed-encode-attend-predict-framework-to-predict-document-similarity.html" rel="alternate"></link><published>2017-07-06T00:00:00+00:00</published><updated>2017-07-06T00:00:00+00:00</updated><author><name>Sujit Pal</name></author><id>tag:pyvideo.org,2017-07-06:pydata-seattle-2017/applying-the-four-step-embed-encode-attend-predict-framework-to-predict-document-similarity.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;This presentation will demonstrate Matthew Honnibal's four-step &amp;quot;Embed, Encode, Attend, Predict&amp;quot; framework to build Deep Neural Networks to do document classification and predict similarity between document and sentence pairs using the Keras Deep Learning Library.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;A new framework for building Natural Language Processing (NLP) models in the Deep Learning era has been proposed by Matthew Honnibal (creator of the SpaCy NLP toolkit). It is composed of the following four steps - Embed, Encode, Attend and Predict. Embed converts incoming text into dense word vectors that encode its meaning as well as its context; Encode adapts the vector to the target task; Attend forces the network to focus on the most important parts of the data; and Predict produces the network's output representation. Word Embeddings have revolutionized many NLP tasks, and today it is the most effective way of representing text as vectors. Combined with the other three steps, this framework provides a principled way to make predictions starting from unstructured text data. This presentation will demonstrate the use of this four step framework to build Deep Neural Networks that do document classification and predict similarity between sentence and document pairs, using the Keras Deep Learning Library for Python.&lt;/p&gt;
</summary></entry><entry><title>Measuring Search Engine Quality using Spark and Python</title><link href="http://pyvideo.org/pydata-amsterdam-2016/measuring-search-engine-quality-using-spark-and-python.html" rel="alternate"></link><published>2016-03-26T00:00:00+00:00</published><updated>2016-03-26T00:00:00+00:00</updated><author><name>Sujit Pal</name></author><id>tag:pyvideo.org,2016-03-26:pydata-amsterdam-2016/measuring-search-engine-quality-using-spark-and-python.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData Amsterdam 2016&lt;/p&gt;
&lt;p&gt;We describe a system built using Python and Apache Spark which measured the effectiveness of different query configurations of an Apache Solr search platform, using click logs for a reference query set of 80,000+ user queries. The system replays the click logs against the engine to compute the Average Click Rank (ACR) metric as a proxy for user satisfaction, providing a way to identify improvements in quality without having to do a production deployment, and ensuring that only improved configurations are submitted to a slow and expensive A/B testing process.&lt;/p&gt;
&lt;p&gt;For each search engine configuration, the ACR is recomputed by replaying the query logs against it and finding the position (or click rank) for the user's selected document. The ACR is computed by averaging those positions across all user queries in the query log. Lower click ranks are indicative of better engine configuration for that query, since it implies that the user found what they were looking for nearer the top of the results. Similarly, a low ACR across all queries is an indicator of good search engine configuration as a whole.&lt;/p&gt;
&lt;p&gt;This system has also been used to analyze user behavior, by partitioning the results across content types, response times, etc, and analyzing differences in click rank distribution. It has also been used to identify and investigate slow queries, resulting in improvements in which have also benefited the search application.&lt;/p&gt;
&lt;p&gt;Slides available here: &lt;a class="reference external" href="http://www.slideshare.net/sujitpal/measuring-search-engine-quality-using-spark-and-python"&gt;http://www.slideshare.net/sujitpal/measuring-search-engine-quality-using-spark-and-python&lt;/a&gt;&lt;/p&gt;
</summary></entry></feed>