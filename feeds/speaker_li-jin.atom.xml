<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="http://pyvideo.org/" rel="alternate"></link><link href="http://pyvideo.org/feeds/speaker_li-jin.atom.xml" rel="self"></link><id>http://pyvideo.org/</id><updated>2017-11-27T00:00:00+00:00</updated><entry><title>Improving Pandas and PySpark performance and interoperability with Apache Arrow</title><link href="http://pyvideo.org/pydata-new-york-city-2017/improving-pandas-and-pyspark-performance-and-interoperability-with-apache-arrow.html" rel="alternate"></link><published>2017-11-27T00:00:00+00:00</published><updated>2017-11-27T00:00:00+00:00</updated><author><name>Li Jin</name></author><id>tag:pyvideo.org,2017-11-27:pydata-new-york-city-2017/improving-pandas-and-pyspark-performance-and-interoperability-with-apache-arrow.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Apache Spark has become a popular and successful way for Python programming to parallelize and scale up data processing. However, it's not well integrated with popular Python tools such as Pandas, and often result in poor performance when using Pandas with PySpark. In this talk, we will demonstrate how we improve PySpark performance with Apache Arrow.&lt;/p&gt;
</summary></entry></feed>